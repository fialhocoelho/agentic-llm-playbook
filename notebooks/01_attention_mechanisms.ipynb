{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Introduction to Transformers\n",
    "\n",
    "## Notebook 01: Attention Mechanisms\n",
    "\n",
    "Welcome to the agentic-llm-playbook! This notebook introduces the core concept of attention mechanisms, the building block of modern LLMs.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the scaled dot-product attention formula\n",
    "- Implement attention from scratch\n",
    "- Visualize attention weights\n",
    "- Explore causal masking for autoregressive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from llm_journey.models import ScaledDotProductAttention\n",
    "from llm_journey.utils import set_seed\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scaled Dot-Product Attention\n",
    "\n",
    "The attention mechanism computes a weighted sum of values based on the similarity between queries and keys:\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "Where:\n",
    "- $Q$ (Query): What we're looking for\n",
    "- $K$ (Key): What we're matching against\n",
    "- $V$ (Value): The actual content to retrieve\n",
    "- $d_k$: Dimension of the key vectors (scaling factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple query, key, value tensors\n",
    "batch_size = 1\n",
    "num_heads = 1\n",
    "seq_len = 5\n",
    "d_k = 8\n",
    "\n",
    "query = torch.randn(batch_size, num_heads, seq_len, d_k)\n",
    "key = torch.randn(batch_size, num_heads, seq_len, d_k)\n",
    "value = torch.randn(batch_size, num_heads, seq_len, d_k)\n",
    "\n",
    "print(f\"Query shape: {query.shape}\")\n",
    "print(f\"Key shape: {key.shape}\")\n",
    "print(f\"Value shape: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply attention\n",
    "attention = ScaledDotProductAttention(dropout=0.0)\n",
    "output, weights = attention(query, key, value)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Attention weights shape: {weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing Attention Weights\n",
    "\n",
    "Let's visualize how each query position attends to different key positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(weights[0, 0].detach().numpy(), cmap='viridis')\n",
    "plt.colorbar(label='Attention Weight')\n",
    "plt.title('Attention Weights Heatmap')\n",
    "plt.xlabel('Key Position')\n",
    "plt.ylabel('Query Position')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Causal Masking for Autoregressive Generation\n",
    "\n",
    "In language modeling, we need to prevent the model from \"looking ahead\" during training. This is achieved through causal masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create causal mask (lower triangular matrix)\n",
    "causal_mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "print(\"Causal mask:\")\n",
    "print(causal_mask[0, 0])\n",
    "\n",
    "# Apply attention with mask\n",
    "output_masked, weights_masked = attention(query, key, value, causal_mask)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(weights_masked[0, 0].detach().numpy(), cmap='viridis')\n",
    "plt.colorbar(label='Attention Weight')\n",
    "plt.title('Causal Masked Attention Weights')\n",
    "plt.xlabel('Key Position')\n",
    "plt.ylabel('Query Position')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Modify the attention visualization to show attention patterns for different random seeds\n",
    "2. Experiment with different sequence lengths and observe how attention patterns change\n",
    "3. Implement a function to compute attention scores manually and verify they match the module output\n",
    "4. Create a custom mask that only allows attending to the previous 3 tokens (sliding window attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Continue to Notebook 02 to learn about Multi-Head Attention and how it extends the basic attention mechanism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Playbook",
   "language": "python",
   "name": "llm-playbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
